#!/usr/bin/env python3
"""
è¨˜æ†¶æŸ¥è©¢å¼•æ“ (Memory Query Engine)
PowerAutomation è¨˜æ†¶ç³»çµ±çš„çµ±ä¸€æŸ¥è©¢æ¥å£

æä¾›è·¨GitHubã€SuperMemoryã€RAGçš„çµ±ä¸€è¨˜æ†¶æŸ¥è©¢åŠŸèƒ½
"""

import os
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import logging
import subprocess

# å°å…¥å…¶ä»–è¨˜æ†¶æ¨¡å¡Š
import sys
sys.path.append('memory-system/memory-storage')
sys.path.append('memory-system/rag-integration')

try:
    from memory_storage import MemoryStorage, StoredMemory
    from rag_integration import RAGIntegration
except ImportError:
    print("âš ï¸ ç„¡æ³•å°å…¥è¨˜æ†¶æ¨¡å¡Šï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataSource(Enum):
    """æ•¸æ“šä¾†æº"""
    GITHUB = ("ğŸ“", "GitHub", "ä»£ç¢¼ç‰ˆæœ¬æ§åˆ¶å’Œå”ä½œæ•¸æ“š")
    SUPERMEMORY = ("ğŸ§ ", "SuperMemory", "é•·æœŸè¨˜æ†¶å’Œä¸Šä¸‹æ–‡æ•¸æ“š")
    RAG = ("ğŸ”", "RAG", "å‘é‡åŒ–èªç¾©æª¢ç´¢æ•¸æ“š")
    LOCAL_MEMORY = ("ğŸ’¾", "LocalMemory", "æœ¬åœ°è¨˜æ†¶å­˜å„²æ•¸æ“š")
    
    def __init__(self, emoji, display_name, description):
        self.emoji = emoji
        self.display_name = display_name
        self.description = description

@dataclass
class QueryResult:
    """æŸ¥è©¢çµæœ"""
    id: str
    content: str
    source: DataSource
    relevance_score: float
    metadata: Dict[str, Any]
    created_at: str
    importance_level: str
    memory_type: str

class MemoryQueryEngine:
    """è¨˜æ†¶æŸ¥è©¢å¼•æ“"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„å€‹æ•¸æ“šæº
        self.memory_storage = None
        self.rag_integration = None
        self.github_data_path = "data/github"
        self.supermemory_data_path = "data/backup/supermemory_workspaces"
        
        self._init_data_sources()
        
    def _init_data_sources(self):
        """åˆå§‹åŒ–æ•¸æ“šæº"""
        try:
            # åˆå§‹åŒ–æœ¬åœ°è¨˜æ†¶å­˜å„²
            self.memory_storage = MemoryStorage()
            logger.info("âœ… æœ¬åœ°è¨˜æ†¶å­˜å„²å·²åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"æœ¬åœ°è¨˜æ†¶å­˜å„²åˆå§‹åŒ–å¤±æ•—: {e}")
            
        try:
            # åˆå§‹åŒ–RAGæ•´åˆ
            self.rag_integration = RAGIntegration()
            logger.info("âœ… RAGæ•´åˆå·²åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"RAGæ•´åˆåˆå§‹åŒ–å¤±æ•—: {e}")
            
    def unified_search(self, 
                      query: str,
                      sources: List[DataSource] = None,
                      memory_type: str = None,
                      importance_level: str = None,
                      time_range_hours: int = None,
                      limit: int = 20) -> List[QueryResult]:
        """çµ±ä¸€æœç´¢æ¥å£"""
        
        if sources is None:
            sources = list(DataSource)
            
        all_results = []
        
        # æœç´¢å„å€‹æ•¸æ“šæº
        for source in sources:
            try:
                if source == DataSource.LOCAL_MEMORY:
                    results = self._search_local_memory(query, memory_type, importance_level, time_range_hours)
                elif source == DataSource.RAG:
                    results = self._search_rag(query)
                elif source == DataSource.GITHUB:
                    results = self._search_github(query)
                elif source == DataSource.SUPERMEMORY:
                    results = self._search_supermemory(query)
                else:
                    continue
                    
                all_results.extend(results)
                
            except Exception as e:
                logger.error(f"æœç´¢ {source.display_name} å¤±æ•—: {e}")
                
        # æŒ‰ç›¸é—œæ€§æ’åºä¸¦é™åˆ¶çµæœæ•¸é‡
        all_results.sort(key=lambda x: x.relevance_score, reverse=True)
        return all_results[:limit]
        
    def _search_local_memory(self, query: str, memory_type: str = None, 
                           importance_level: str = None, time_range_hours: int = None) -> List[QueryResult]:
        """æœç´¢æœ¬åœ°è¨˜æ†¶å­˜å„²"""
        if not self.memory_storage:
            return []
            
        try:
            # æ§‹å»ºæœç´¢åƒæ•¸
            search_params = {
                'query': query,
                'memory_type': memory_type,
                'limit': 50
            }
            
            if importance_level:
                # æ ¹æ“šé‡è¦æ€§ç´šåˆ¥è¨­ç½®åˆ†æ•¸ç¯„åœ
                importance_ranges = {
                    'Critical': (9, 10),
                    'Important': (6, 8),
                    'Normal': (3, 5),
                    'Low': (1, 2)
                }
                if importance_level in importance_ranges:
                    min_score, max_score = importance_ranges[importance_level]
                    search_params['min_importance'] = min_score
                    search_params['max_importance'] = max_score
                    
            memories = self.memory_storage.search_memories(**search_params)
            
            results = []
            for memory in memories:
                # è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸ï¼ˆç°¡å–®çš„é—œéµè©åŒ¹é…ï¼‰
                relevance = self._calculate_text_relevance(query, memory.content)
                
                result = QueryResult(
                    id=memory.id,
                    content=memory.content,
                    source=DataSource.LOCAL_MEMORY,
                    relevance_score=relevance,
                    metadata={
                        'tags': memory.tags,
                        'session_id': memory.session_id,
                        'access_count': memory.access_count
                    },
                    created_at=memory.created_at,
                    importance_level=memory.importance_level,
                    memory_type=memory.memory_type
                )
                results.append(result)
                
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢æœ¬åœ°è¨˜æ†¶å¤±æ•—: {e}")
            return []
            
    def _search_rag(self, query: str) -> List[QueryResult]:
        """æœç´¢RAGå‘é‡æ•¸æ“šåº«"""
        if not self.rag_integration:
            return []
            
        try:
            # èªç¾©æœç´¢
            semantic_results = self.rag_integration.semantic_search(query, top_k=10, threshold=0.3)
            
            results = []
            for memory_id, similarity_score in semantic_results:
                # ç²å–å‘é‡åŒ–è¨˜æ†¶çš„è©³ç´°ä¿¡æ¯
                if memory_id in self.rag_integration.vectors_db:
                    vectorized_memory = self.rag_integration.vectors_db[memory_id]
                    
                    result = QueryResult(
                        id=memory_id,
                        content=vectorized_memory.content,
                        source=DataSource.RAG,
                        relevance_score=similarity_score,
                        metadata=vectorized_memory.metadata,
                        created_at=vectorized_memory.created_at,
                        importance_level="Unknown",
                        memory_type="semantic_vector"
                    )
                    results.append(result)
                    
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢RAGå¤±æ•—: {e}")
            return []
            
    def _search_github(self, query: str) -> List[QueryResult]:
        """æœç´¢GitHubæ•¸æ“š"""
        try:
            results = []
            
            # æœç´¢Gitæäº¤è¨˜éŒ„
            try:
                git_results = subprocess.run([
                    'git', 'log', '--grep', query, '--oneline', '-10'
                ], capture_output=True, text=True, cwd='.')
                
                if git_results.returncode == 0:
                    for line in git_results.stdout.strip().split('\n'):
                        if line.strip():
                            commit_hash = line.split()[0]
                            commit_msg = ' '.join(line.split()[1:])
                            
                            relevance = self._calculate_text_relevance(query, commit_msg)
                            
                            result = QueryResult(
                                id=f"git_{commit_hash}",
                                content=f"Commit: {commit_msg}",
                                source=DataSource.GITHUB,
                                relevance_score=relevance,
                                metadata={'commit_hash': commit_hash, 'type': 'commit'},
                                created_at=datetime.now().isoformat(),
                                importance_level="Normal",
                                memory_type="git_commit"
                            )
                            results.append(result)
                            
            except Exception as e:
                logger.warning(f"æœç´¢Gitæäº¤å¤±æ•—: {e}")
                
            # æœç´¢é …ç›®æ–‡ä»¶ä¸­çš„å…§å®¹
            try:
                grep_results = subprocess.run([
                    'grep', '-r', '-i', '--include=*.py', '--include=*.md', 
                    '--include=*.json', query, '.'
                ], capture_output=True, text=True)
                
                if grep_results.returncode == 0:
                    for line in grep_results.stdout.strip().split('\n')[:5]:  # é™åˆ¶çµæœæ•¸é‡
                        if ':' in line:
                            file_path, content = line.split(':', 1)
                            
                            relevance = self._calculate_text_relevance(query, content)
                            
                            result = QueryResult(
                                id=f"file_{hash(file_path + content)}",
                                content=f"File: {file_path}\nContent: {content.strip()}",
                                source=DataSource.GITHUB,
                                relevance_score=relevance,
                                metadata={'file_path': file_path, 'type': 'file_content'},
                                created_at=datetime.now().isoformat(),
                                importance_level="Normal",
                                memory_type="file_content"
                            )
                            results.append(result)
                            
            except Exception as e:
                logger.warning(f"æœç´¢æ–‡ä»¶å…§å®¹å¤±æ•—: {e}")
                
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢GitHubå¤±æ•—: {e}")
            return []
            
    def _search_supermemory(self, query: str) -> List[QueryResult]:
        """æœç´¢SuperMemoryæ•¸æ“š"""
        try:
            results = []
            
            # æœç´¢SuperMemoryå·¥ä½œå€æ–‡ä»¶
            if os.path.exists(self.supermemory_data_path):
                for root, dirs, files in os.walk(self.supermemory_data_path):
                    for file in files:
                        if file.endswith(('.json', '.txt', '.md')):
                            file_path = os.path.join(root, file)
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    
                                if query.lower() in content.lower():
                                    relevance = self._calculate_text_relevance(query, content)
                                    
                                    result = QueryResult(
                                        id=f"supermemory_{hash(file_path)}",
                                        content=f"SuperMemory: {file}\nContent: {content[:200]}...",
                                        source=DataSource.SUPERMEMORY,
                                        relevance_score=relevance,
                                        metadata={'file_path': file_path, 'type': 'supermemory_file'},
                                        created_at=datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
                                        importance_level="Normal",
                                        memory_type="supermemory_data"
                                    )
                                    results.append(result)
                                    
                            except Exception as e:
                                logger.warning(f"è®€å–SuperMemoryæ–‡ä»¶å¤±æ•— {file_path}: {e}")
                                
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢SuperMemoryå¤±æ•—: {e}")
            return []
            
    def _calculate_text_relevance(self, query: str, text: str) -> float:
        """è¨ˆç®—æ–‡æœ¬ç›¸é—œæ€§åˆ†æ•¸"""
        try:
            query_lower = query.lower()
            text_lower = text.lower()
            
            # ç°¡å–®çš„é—œéµè©åŒ¹é…è©•åˆ†
            query_words = query_lower.split()
            text_words = text_lower.split()
            
            if not query_words:
                return 0.0
                
            matches = 0
            for word in query_words:
                if word in text_lower:
                    matches += 1
                    
            # åŸºç¤ç›¸é—œæ€§åˆ†æ•¸
            base_score = matches / len(query_words)
            
            # è€ƒæ…®å®Œæ•´åŒ¹é…
            if query_lower in text_lower:
                base_score += 0.3
                
            # è€ƒæ…®è©é »
            total_occurrences = sum(text_lower.count(word) for word in query_words)
            frequency_bonus = min(total_occurrences * 0.1, 0.5)
            
            return min(base_score + frequency_bonus, 1.0)
            
        except Exception as e:
            logger.error(f"è¨ˆç®—ç›¸é—œæ€§å¤±æ•—: {e}")
            return 0.0
            
    def get_data_source_statistics(self) -> Dict[str, Any]:
        """ç²å–å„æ•¸æ“šæºçµ±è¨ˆä¿¡æ¯"""
        stats = {}
        
        # æœ¬åœ°è¨˜æ†¶å­˜å„²çµ±è¨ˆ
        if self.memory_storage:
            try:
                local_stats = self.memory_storage.get_statistics()
                stats['local_memory'] = local_stats
            except Exception as e:
                stats['local_memory'] = {'error': str(e)}
                
        # RAGçµ±è¨ˆ
        if self.rag_integration:
            try:
                rag_stats = self.rag_integration.get_statistics()
                stats['rag'] = rag_stats
            except Exception as e:
                stats['rag'] = {'error': str(e)}
                
        # GitHubçµ±è¨ˆ
        try:
            git_commit_count = subprocess.run([
                'git', 'rev-list', '--count', 'HEAD'
            ], capture_output=True, text=True)
            
            if git_commit_count.returncode == 0:
                stats['github'] = {
                    'total_commits': int(git_commit_count.stdout.strip()),
                    'repository_path': os.getcwd()
                }
        except Exception as e:
            stats['github'] = {'error': str(e)}
            
        # SuperMemoryçµ±è¨ˆ
        try:
            supermemory_files = 0
            if os.path.exists(self.supermemory_data_path):
                for root, dirs, files in os.walk(self.supermemory_data_path):
                    supermemory_files += len(files)
                    
            stats['supermemory'] = {
                'total_files': supermemory_files,
                'workspace_path': self.supermemory_data_path
            }
        except Exception as e:
            stats['supermemory'] = {'error': str(e)}
            
        return stats
        
    def format_search_results(self, results: List[QueryResult]) -> str:
        """æ ¼å¼åŒ–æœç´¢çµæœ"""
        if not results:
            return "ğŸ” æœªæ‰¾åˆ°ç›¸é—œè¨˜æ†¶"
            
        output = [f"ğŸ” æ‰¾åˆ° {len(results)} æ¢ç›¸é—œè¨˜æ†¶:\n"]
        
        for i, result in enumerate(results, 1):
            source_info = f"{result.source.emoji} [{result.source.display_name}]"
            relevance_info = f"ç›¸é—œæ€§: {result.relevance_score:.2f}"
            
            output.append(f"{i}. {source_info} {relevance_info}")
            output.append(f"   {result.content[:100]}...")
            output.append(f"   é¡å‹: {result.memory_type} | é‡è¦æ€§: {result.importance_level}")
            output.append(f"   æ™‚é–“: {result.created_at}")
            output.append("")
            
        return "\n".join(output)

# å…¨å±€å¯¦ä¾‹
memory_query_engine = MemoryQueryEngine()

# CLIæ¥å£å‡½æ•¸
def search_memories(query: str, source: str = None, memory_type: str = None, 
                   importance: str = None, hours: int = None, limit: int = 20):
    """CLIæœç´¢æ¥å£"""
    
    # è§£ææ•¸æ“šæº
    sources = None
    if source:
        source_map = {
            'github': DataSource.GITHUB,
            'supermemory': DataSource.SUPERMEMORY,
            'rag': DataSource.RAG,
            'local': DataSource.LOCAL_MEMORY
        }
        if source.lower() in source_map:
            sources = [source_map[source.lower()]]
            
    # åŸ·è¡Œæœç´¢
    results = memory_query_engine.unified_search(
        query=query,
        sources=sources,
        memory_type=memory_type,
        importance_level=importance,
        time_range_hours=hours,
        limit=limit
    )
    
    return memory_query_engine.format_search_results(results)

def show_data_sources():
    """é¡¯ç¤ºæ•¸æ“šæºä¿¡æ¯"""
    stats = memory_query_engine.get_data_source_statistics()
    
    output = ["ğŸ“Š è¨˜æ†¶ç³»çµ±æ•¸æ“šæºçµ±è¨ˆ:\n"]
    
    for source in DataSource:
        output.append(f"{source.emoji} {source.display_name} - {source.description}")
        
        source_key = source.display_name.lower().replace('memory', '_memory')
        if source_key in stats:
            source_stats = stats[source_key]
            if 'error' in source_stats:
                output.append(f"   âŒ éŒ¯èª¤: {source_stats['error']}")
            else:
                for key, value in source_stats.items():
                    output.append(f"   {key}: {value}")
        output.append("")
        
    return "\n".join(output)

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python3 memory_query_engine.py search <æŸ¥è©¢å…§å®¹>")
        print("  python3 memory_query_engine.py search <æŸ¥è©¢å…§å®¹> --source github")
        print("  python3 memory_query_engine.py search <æŸ¥è©¢å…§å®¹> --type problem_solving")
        print("  python3 memory_query_engine.py search <æŸ¥è©¢å…§å®¹> --importance Critical")
        print("  python3 memory_query_engine.py sources")
        sys.exit(1)
        
    command = sys.argv[1]
    
    if command == "search" and len(sys.argv) > 2:
        query = sys.argv[2]
        
        # è§£æå¯é¸åƒæ•¸
        source = None
        memory_type = None
        importance = None
        
        for i in range(3, len(sys.argv), 2):
            if i + 1 < len(sys.argv):
                if sys.argv[i] == "--source":
                    source = sys.argv[i + 1]
                elif sys.argv[i] == "--type":
                    memory_type = sys.argv[i + 1]
                elif sys.argv[i] == "--importance":
                    importance = sys.argv[i + 1]
                    
        result = search_memories(query, source, memory_type, importance)
        print(result)
        
    elif command == "sources":
        result = show_data_sources()
        print(result)
        
    else:
        print("âŒ æœªçŸ¥å‘½ä»¤")
        sys.exit(1)

