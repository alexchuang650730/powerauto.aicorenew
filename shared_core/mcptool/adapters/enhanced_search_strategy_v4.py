"""
å¢å¼·æœç´¢ç­–ç•¥v4.0 - æ™ºèƒ½å·¥å…·ç™¼ç¾å’ŒåŒ¹é…ç®—æ³•

åŸºæ–¼å·¥å…·é¸æ“‡å™¨v4.0çš„æˆåŠŸï¼Œé€²ä¸€æ­¥å¢å¼·æœç´¢ç­–ç•¥
ç›®æ¨™ï¼šæé«˜å¤–éƒ¨å·¥å…·ç™¼ç¾çš„æº–ç¢ºæ€§å’ŒåŒ¹é…åº¦
"""

import re
import json
import random
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

@dataclass
class SearchResult:
    """æœç´¢çµæœ"""
    tool_name: str
    description: str
    confidence: float
    service_type: str
    match_reasons: List[str]
    search_query: str

@dataclass
class ToolMatch:
    """å·¥å…·åŒ¹é…çµæœ"""
    tool: SearchResult
    match_score: float
    relevance_factors: Dict[str, float]

class EnhancedSearchStrategyV4:
    """å¢å¼·æœç´¢ç­–ç•¥v4.0"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœç´¢ç­–ç•¥"""
        self.search_templates = self._build_search_templates()
        self.tool_databases = self._build_tool_databases()
        self.matching_algorithms = self._build_matching_algorithms()
        self.service_priorities = self._build_service_priorities()
        
    def _build_search_templates(self) -> Dict[str, List[str]]:
        """æ§‹å»ºæœç´¢æ¨¡æ¿"""
        return {
            "factual_search": [
                "{entity} current information API",
                "real-time {entity} data service",
                "{entity} fact checking tool",
                "current {entity} status API",
                "live {entity} information service",
                "{entity} verification tool MCP",
                "real-time fact API {entity}",
                "{entity} current data connector"
            ],
            "academic_paper": [
                "{topic} research paper API",
                "academic paper search {topic}",
                "{topic} scholarly article tool",
                "research database {topic} API",
                "{topic} citation analysis tool",
                "academic search engine {topic}",
                "{topic} paper analysis service",
                "scholarly {topic} research tool"
            ],
            "automation": [
                "{process} automation tool",
                "workflow automation {process}",
                "{process} process automation API",
                "automated {process} service",
                "{process} workflow connector",
                "business process {process} tool",
                "{process} automation platform",
                "robotic {process} automation"
            ],
            "calculation": [
                "{problem} mathematical solver",
                "calculation API {problem}",
                "{problem} computation service",
                "mathematical {problem} tool",
                "{problem} solver API",
                "computational {problem} engine",
                "{problem} calculation platform",
                "math API {problem} solver"
            ],
            "complex_analysis": [
                "{topic} analysis service",
                "analytical {topic} tool",
                "{topic} comparison API",
                "deep analysis {topic} service",
                "{topic} evaluation tool",
                "comprehensive {topic} analyzer",
                "{topic} assessment platform",
                "analytical reasoning {topic} API"
            ],
            "simple_qa": [
                "{topic} knowledge API",
                "general {topic} information service",
                "{topic} Q&A tool",
                "knowledge base {topic} API",
                "{topic} information retrieval",
                "general knowledge {topic} service",
                "{topic} definition API",
                "encyclopedia {topic} tool"
            ]
        }
    
    def _build_tool_databases(self) -> Dict[str, List[Dict[str, Any]]]:
        """æ§‹å»ºå·¥å…·æ•¸æ“šåº«ï¼ˆæ¨¡æ“¬å¤–éƒ¨æœå‹™ï¼‰"""
        return {
            "mcp.so": [
                {
                    "name": "arxiv_mcp_server",
                    "description": "Academic paper search and analysis from ArXiv database",
                    "categories": ["academic", "research", "paper", "scientific"],
                    "capabilities": ["search", "analysis", "citation", "full_text"],
                    "confidence_base": 0.90
                },
                {
                    "name": "realtime_fact_checker",
                    "description": "Real-time fact verification and current information retrieval",
                    "categories": ["factual", "current", "verification", "real-time"],
                    "capabilities": ["fact_check", "current_data", "verification"],
                    "confidence_base": 0.88
                },
                {
                    "name": "knowledge_graph_api",
                    "description": "Comprehensive knowledge graph for general information",
                    "categories": ["knowledge", "general", "information", "qa"],
                    "capabilities": ["knowledge_retrieval", "entity_info", "relationships"],
                    "confidence_base": 0.85
                },
                {
                    "name": "math_solver_pro",
                    "description": "Advanced mathematical problem solver and calculator",
                    "categories": ["math", "calculation", "solver", "computation"],
                    "capabilities": ["calculation", "equation_solving", "formula_evaluation"],
                    "confidence_base": 0.92
                }
            ],
            "aci.dev": [
                {
                    "name": "ai_analysis_engine",
                    "description": "Advanced AI-powered analysis and comparison service",
                    "categories": ["analysis", "comparison", "evaluation", "reasoning"],
                    "capabilities": ["deep_analysis", "comparison", "evaluation", "reasoning"],
                    "confidence_base": 0.87
                },
                {
                    "name": "intelligent_data_processor",
                    "description": "Intelligent data processing and analysis platform",
                    "categories": ["data", "processing", "analysis", "intelligence"],
                    "capabilities": ["data_analysis", "pattern_recognition", "insights"],
                    "confidence_base": 0.84
                },
                {
                    "name": "concept_analyzer",
                    "description": "Advanced concept analysis and definition service",
                    "categories": ["concept", "definition", "explanation", "analysis"],
                    "capabilities": ["concept_analysis", "definition", "explanation"],
                    "confidence_base": 0.82
                }
            ],
            "zapier": [
                {
                    "name": "workflow_automation_hub",
                    "description": "Comprehensive workflow automation and integration platform",
                    "categories": ["workflow", "automation", "integration", "process"],
                    "capabilities": ["workflow_design", "automation", "integration", "scheduling"],
                    "confidence_base": 0.86
                },
                {
                    "name": "process_optimizer",
                    "description": "Business process optimization and automation tool",
                    "categories": ["process", "optimization", "business", "automation"],
                    "capabilities": ["process_analysis", "optimization", "automation_design"],
                    "confidence_base": 0.83
                },
                {
                    "name": "integration_connector",
                    "description": "Universal integration and connection service",
                    "categories": ["integration", "connection", "api", "sync"],
                    "capabilities": ["api_integration", "data_sync", "connection_management"],
                    "confidence_base": 0.80
                }
            ]
        }
    
    def _build_matching_algorithms(self) -> Dict[str, Dict[str, Any]]:
        """æ§‹å»ºåŒ¹é…ç®—æ³•"""
        return {
            "keyword_matching": {
                "weight": 0.35,
                "algorithm": self._keyword_match_score
            },
            "category_matching": {
                "weight": 0.25,
                "algorithm": self._category_match_score
            },
            "capability_matching": {
                "weight": 0.25,
                "algorithm": self._capability_match_score
            },
            "semantic_similarity": {
                "weight": 0.15,
                "algorithm": self._semantic_similarity_score
            }
        }
    
    def _build_service_priorities(self) -> Dict[str, float]:
        """æ§‹å»ºæœå‹™å„ªå…ˆç´š"""
        return {
            "mcp.so": 1.0,      # æœ€é«˜å„ªå…ˆç´šï¼Œå°ˆé–€çš„MCPå·¥å…·
            "aci.dev": 0.9,     # é«˜å„ªå…ˆç´šï¼ŒAIæœå‹™
            "zapier": 0.8       # ä¸­ç­‰å„ªå…ˆç´šï¼Œè‡ªå‹•åŒ–å¹³å°
        }
    
    def generate_search_queries(self, question: str, question_type: str) -> List[str]:
        """ç”Ÿæˆæœç´¢æŸ¥è©¢"""
        templates = self.search_templates.get(question_type, [])
        
        # æå–é—œéµå¯¦é«”å’Œä¸»é¡Œ
        entities = self._extract_entities(question)
        topics = self._extract_topics(question, question_type)
        
        queries = []
        
        # åŸºæ–¼æ¨¡æ¿ç”ŸæˆæŸ¥è©¢
        for template in templates:
            # è™•ç†å¯¦é«”æ¨¡æ¿
            if "{entity}" in template:
                for entity in entities[:2]:  # æœ€å¤šä½¿ç”¨2å€‹å¯¦é«”
                    query = template.format(entity=entity)
                    queries.append(query)
            
            # è™•ç†ä¸»é¡Œæ¨¡æ¿
            if "{topic}" in template:
                for topic in topics[:2]:  # æœ€å¤šä½¿ç”¨2å€‹ä¸»é¡Œ
                    query = template.format(topic=topic)
                    queries.append(query)
            
            # è™•ç†å•é¡Œæ¨¡æ¿
            if "{problem}" in template:
                for topic in topics[:2]:
                    query = template.format(problem=topic)
                    queries.append(query)
            
            # è™•ç†æµç¨‹æ¨¡æ¿
            if "{process}" in template:
                for topic in topics[:2]:
                    query = template.format(process=topic)
                    queries.append(query)
        
        # æ·»åŠ é€šç”¨æŸ¥è©¢
        queries.extend([
            f"{question_type} tool API",
            f"{question_type} service MCP",
            f"best {question_type} automation tool"
        ])
        
        return list(set(queries))  # å»é‡
    
    def _extract_entities(self, question: str) -> List[str]:
        """æå–å¯¦é«”"""
        # ç°¡åŒ–çš„å¯¦é«”æå–
        entities = []
        
        # æå–æ–¹æ‹¬è™Ÿä¸­çš„å¯¦é«”
        bracket_entities = re.findall(r'\[([^\]]+)\]', question)
        entities.extend(bracket_entities)
        
        # æå–#å¾Œçš„æ•¸å­—å¯¦é«”
        number_entities = re.findall(r'#(\d+)', question)
        entities.extend([f"item_{num}" for num in number_entities])
        
        # æå–å¸¸è¦‹å¯¦é«”æ¨¡å¼
        entity_patterns = [
            r'about\s+(\w+)',
            r'of\s+(\w+)',
            r'for\s+(\w+)',
            r'(\w+)\s+record',
            r'(\w+)\s+problem'
        ]
        
        for pattern in entity_patterns:
            matches = re.findall(pattern, question.lower())
            entities.extend(matches)
        
        return entities[:5]  # æœ€å¤šè¿”å›5å€‹å¯¦é«”
    
    def _extract_topics(self, question: str, question_type: str) -> List[str]:
        """æå–ä¸»é¡Œ"""
        topics = []
        
        # åŸºæ–¼å•é¡Œé¡å‹çš„ä¸»é¡Œæå–
        type_topics = {
            "factual_search": ["information", "data", "facts"],
            "academic_paper": ["research", "academic", "scholarly"],
            "automation": ["workflow", "process", "automation"],
            "calculation": ["mathematical", "computation", "calculation"],
            "complex_analysis": ["analysis", "comparison", "evaluation"],
            "simple_qa": ["knowledge", "information", "general"]
        }
        
        topics.extend(type_topics.get(question_type, []))
        
        # æå–å•é¡Œä¸­çš„é—œéµè©ä½œç‚ºä¸»é¡Œ
        keywords = re.findall(r'\b\w{4,}\b', question.lower())
        topics.extend(keywords[:3])
        
        return topics[:5]  # æœ€å¤šè¿”å›5å€‹ä¸»é¡Œ
    
    def search_tools(self, queries: List[str], question_type: str) -> List[SearchResult]:
        """æœç´¢å·¥å…·"""
        all_results = []
        
        for service, tools in self.tool_databases.items():
            for tool in tools:
                for query in queries:
                    match_score = self._calculate_match_score(query, tool, question_type)
                    
                    if match_score > 0.3:  # æœ€ä½åŒ¹é…é–¾å€¼
                        confidence = tool["confidence_base"] * match_score
                        confidence *= self.service_priorities[service]  # æœå‹™å„ªå…ˆç´šèª¿æ•´
                        
                        result = SearchResult(
                            tool_name=tool["name"],
                            description=tool["description"],
                            confidence=confidence,
                            service_type=service,
                            match_reasons=self._get_match_reasons(query, tool),
                            search_query=query
                        )
                        all_results.append(result)
        
        # å»é‡ä¸¦æ’åº
        unique_results = {}
        for result in all_results:
            if result.tool_name not in unique_results or result.confidence > unique_results[result.tool_name].confidence:
                unique_results[result.tool_name] = result
        
        sorted_results = sorted(unique_results.values(), key=lambda x: x.confidence, reverse=True)
        return sorted_results[:10]  # è¿”å›å‰10å€‹çµæœ
    
    def _calculate_match_score(self, query: str, tool: Dict[str, Any], question_type: str) -> float:
        """è¨ˆç®—åŒ¹é…åˆ†æ•¸"""
        total_score = 0.0
        
        for algorithm_name, config in self.matching_algorithms.items():
            algorithm = config["algorithm"]
            weight = config["weight"]
            score = algorithm(query, tool, question_type)
            total_score += score * weight
        
        return min(1.0, total_score)
    
    def _keyword_match_score(self, query: str, tool: Dict[str, Any], question_type: str) -> float:
        """é—œéµè©åŒ¹é…åˆ†æ•¸"""
        query_words = set(query.lower().split())
        tool_words = set()
        
        # æ”¶é›†å·¥å…·çš„æ‰€æœ‰æ–‡æœ¬
        tool_words.update(tool["name"].lower().split())
        tool_words.update(tool["description"].lower().split())
        tool_words.update(tool["categories"])
        tool_words.update(tool["capabilities"])
        
        # è¨ˆç®—äº¤é›†
        intersection = query_words.intersection(tool_words)
        union = query_words.union(tool_words)
        
        if not union:
            return 0.0
        
        return len(intersection) / len(query_words)  # Jaccardç›¸ä¼¼åº¦çš„è®Šé«”
    
    def _category_match_score(self, query: str, tool: Dict[str, Any], question_type: str) -> float:
        """é¡åˆ¥åŒ¹é…åˆ†æ•¸"""
        query_lower = query.lower()
        categories = tool["categories"]
        
        matches = sum(1 for category in categories if category in query_lower)
        return matches / len(categories) if categories else 0.0
    
    def _capability_match_score(self, query: str, tool: Dict[str, Any], question_type: str) -> float:
        """èƒ½åŠ›åŒ¹é…åˆ†æ•¸"""
        # å•é¡Œé¡å‹åˆ°èƒ½åŠ›çš„æ˜ å°„
        type_capabilities = {
            "factual_search": ["fact_check", "current_data", "verification", "real_time"],
            "academic_paper": ["search", "analysis", "citation", "research"],
            "automation": ["workflow_design", "automation", "integration", "process"],
            "calculation": ["calculation", "equation_solving", "computation", "math"],
            "complex_analysis": ["deep_analysis", "comparison", "evaluation", "reasoning"],
            "simple_qa": ["knowledge_retrieval", "information", "qa", "general"]
        }
        
        required_capabilities = type_capabilities.get(question_type, [])
        tool_capabilities = tool["capabilities"]
        
        if not required_capabilities:
            return 0.5
        
        matches = sum(1 for cap in required_capabilities if any(tc in cap or cap in tc for tc in tool_capabilities))
        return matches / len(required_capabilities)
    
    def _semantic_similarity_score(self, query: str, tool: Dict[str, Any], question_type: str) -> float:
        """èªç¾©ç›¸ä¼¼åº¦åˆ†æ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        # ç°¡åŒ–çš„èªç¾©ç›¸ä¼¼åº¦è¨ˆç®—
        query_lower = query.lower()
        tool_text = f"{tool['name']} {tool['description']}".lower()
        
        # è¨ˆç®—å…±åŒçš„èªç¾©è©æ ¹
        semantic_matches = 0
        semantic_pairs = [
            ("search", "find"), ("analysis", "analyze"), ("automation", "automate"),
            ("calculation", "compute"), ("information", "data"), ("current", "real-time"),
            ("academic", "scholarly"), ("paper", "research"), ("fact", "truth"),
            ("workflow", "process"), ("tool", "service"), ("api", "connector")
        ]
        
        for word1, word2 in semantic_pairs:
            if (word1 in query_lower and word2 in tool_text) or (word2 in query_lower and word1 in tool_text):
                semantic_matches += 1
        
        return min(1.0, semantic_matches * 0.2)
    
    def _get_match_reasons(self, query: str, tool: Dict[str, Any]) -> List[str]:
        """ç²å–åŒ¹é…åŸå› """
        reasons = []
        
        query_words = set(query.lower().split())
        tool_words = set(tool["name"].lower().split() + tool["description"].lower().split())
        
        common_words = query_words.intersection(tool_words)
        if common_words:
            reasons.append(f"é—œéµè©åŒ¹é…: {', '.join(list(common_words)[:3])}")
        
        category_matches = [cat for cat in tool["categories"] if cat in query.lower()]
        if category_matches:
            reasons.append(f"é¡åˆ¥åŒ¹é…: {', '.join(category_matches[:2])}")
        
        return reasons
    
    def execute_enhanced_search(self, question: str, question_type: str) -> List[SearchResult]:
        """åŸ·è¡Œå¢å¼·æœç´¢"""
        print(f"ğŸ” å¢å¼·æœç´¢ç­–ç•¥v4.0: {question[:50]}...")
        print(f"ğŸ“Š å•é¡Œé¡å‹: {question_type}")
        
        # ç”Ÿæˆæœç´¢æŸ¥è©¢
        queries = self.generate_search_queries(question, question_type)
        print(f"ğŸ” ç”ŸæˆæŸ¥è©¢: {len(queries)}å€‹")
        
        # æœç´¢å·¥å…·
        results = self.search_tools(queries, question_type)
        print(f"ğŸ› ï¸ ç™¼ç¾å·¥å…·: {len(results)}å€‹")
        
        # é¡¯ç¤ºå‰3å€‹çµæœ
        for i, result in enumerate(results[:3], 1):
            print(f"  {i}. {result.tool_name} ({result.service_type})")
            print(f"     ä¿¡å¿ƒåº¦: {result.confidence:.2%}")
            print(f"     åŒ¹é…åŸå› : {'; '.join(result.match_reasons)}")
        
        return results

def test_enhanced_search_strategy():
    """æ¸¬è©¦å¢å¼·æœç´¢ç­–ç•¥v4.0"""
    print("ğŸ§ª æ¸¬è©¦å¢å¼·æœç´¢ç­–ç•¥v4.0")
    print("=" * 60)
    
    search_strategy = EnhancedSearchStrategyV4()
    
    # æ¸¬è©¦ä¸åŒé¡å‹çš„å•é¡Œ
    test_cases = [
        ("What is the current record/fact about entity_13?", "factual_search"),
        ("What is the specific value mentioned in research paper #40?", "academic_paper"),
        ("How to automate workflow process?", "automation"),
        ("Calculate the result of mathematical problem #1", "calculation"),
        ("Analyze and compare deep learning vs traditional ML", "complex_analysis"),
        ("What is artificial intelligence?", "simple_qa")
    ]
    
    results_summary = []
    
    for question, question_type in test_cases:
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æ¸¬è©¦å•é¡Œ: {question}")
        
        results = search_strategy.execute_enhanced_search(question, question_type)
        
        if results:
            best_result = results[0]
            results_summary.append({
                "question_type": question_type,
                "best_tool": best_result.tool_name,
                "confidence": best_result.confidence,
                "service": best_result.service_type,
                "found_tools": len(results)
            })
        else:
            results_summary.append({
                "question_type": question_type,
                "best_tool": "none",
                "confidence": 0.0,
                "service": "none",
                "found_tools": 0
            })
    
    # çµ±è¨ˆçµæœ
    print(f"\n{'='*60}")
    print("ğŸ“Š æœç´¢ç­–ç•¥æ¸¬è©¦ç¸½çµ:")
    
    avg_confidence = sum(r["confidence"] for r in results_summary) / len(results_summary)
    avg_tools_found = sum(r["found_tools"] for r in results_summary) / len(results_summary)
    success_rate = sum(1 for r in results_summary if r["confidence"] > 0.7) / len(results_summary)
    
    print(f"å¹³å‡ä¿¡å¿ƒåº¦: {avg_confidence:.2%}")
    print(f"å¹³å‡ç™¼ç¾å·¥å…·æ•¸: {avg_tools_found:.1f}")
    print(f"é«˜ä¿¡å¿ƒåº¦åŒ¹é…ç‡: {success_rate:.1%} (ä¿¡å¿ƒåº¦>70%)")
    
    # æŒ‰æœå‹™é¡å‹çµ±è¨ˆ
    service_stats = {}
    for result in results_summary:
        service = result["service"]
        if service != "none":
            service_stats[service] = service_stats.get(service, 0) + 1
    
    print(f"æœå‹™åˆ†ä½ˆ: {service_stats}")
    
    return results_summary

if __name__ == "__main__":
    test_enhanced_search_strategy()

