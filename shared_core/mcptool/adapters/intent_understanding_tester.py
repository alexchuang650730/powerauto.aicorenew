"""
æ„åœ–ç†è§£æ•ˆæœæ¸¬è©¦ - ç¶œåˆæ¸¬è©¦æ™ºèƒ½å·¥å…·é¸æ“‡å’Œå­¸ç¿’åé¥‹ç³»çµ±

æ¸¬è©¦å…§å®¹ï¼š
1. æ™ºèƒ½å·¥å…·é¸æ“‡æº–ç¢ºæ€§
2. å­¸ç¿’åé¥‹æ©Ÿåˆ¶æ•ˆæœ
3. å…œåº•æ©Ÿåˆ¶è§¸ç™¼é‚è¼¯
4. MCPå·¥å…·æ¨è–¦æº–ç¢ºæ€§
"""

import sys
import json
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from intelligent_tool_selector import select_best_tool, ToolType
from learning_feedback_system import (
    record_tool_execution, ExecutionResult, 
    check_fallback_needed, get_mcp_tool_suggestions,
    get_learning_statistics
)

class IntentUnderstandingTester:
    """æ„åœ–ç†è§£æ¸¬è©¦å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦å™¨"""
        self.test_cases = [
            {
                "question": "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
                "expected_primary": ToolType.GEMINI,
                "complexity": "simple",
                "description": "ç°¡å–®çŸ¥è­˜å•ç­”"
            },
            {
                "question": "è«‹è©³ç´°åˆ†ææ·±åº¦å­¸ç¿’å’Œå‚³çµ±æ©Ÿå™¨å­¸ç¿’çš„å€åˆ¥ï¼ŒåŒ…æ‹¬ç®—æ³•åŸç†ã€æ‡‰ç”¨å ´æ™¯å’Œå„ªç¼ºé»",
                "expected_primary": ToolType.CLAUDE,
                "complexity": "complex",
                "description": "è¤‡é›œåˆ†æå•é¡Œ"
            },
            {
                "question": "Eliud Kipchogeçš„æœ€æ–°é¦¬æ‹‰æ¾ä¸–ç•Œç´€éŒ„æ˜¯å¤šå°‘ï¼Ÿä»€éº¼æ™‚å€™å‰µé€ çš„ï¼Ÿ",
                "expected_primary": ToolType.WEBAGENT,
                "complexity": "medium",
                "description": "éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯"
            },
            {
                "question": "è«‹è¨ˆç®—å¾1åŠ åˆ°100çš„å’Œï¼Œä¸¦è©³ç´°èªªæ˜è¨ˆç®—æ­¥é©Ÿå’Œæ•¸å­¸åŸç†",
                "expected_primary": ToolType.SEQUENTIAL_THINKING,
                "complexity": "medium",
                "description": "éœ€è¦é€æ­¥è¨ˆç®—"
            },
            {
                "question": "æœç´¢ä¸¦åˆ†æ2024å¹´æœ€æ–°çš„AIç™¼å±•è¶¨å‹¢ï¼Œç„¶å¾Œèˆ‡2023å¹´é€²è¡Œå°æ¯”",
                "expected_primary": ToolType.WEBAGENT,
                "complexity": "complex",
                "description": "æ··åˆæ¨¡å¼ï¼šæœç´¢+åˆ†æ"
            },
            {
                "question": "æˆ‘éœ€è¦ä¸€å€‹èƒ½å¤ è‡ªå‹•è¨˜éŒ„æˆ‘æ¯å¤©å­¸ç¿’é€²åº¦çš„å·¥å…·",
                "expected_primary": None,  # å¯èƒ½è§¸ç™¼å·¥å…·å‰µå»º
                "complexity": "medium",
                "description": "å¯èƒ½éœ€è¦æ–°å·¥å…·"
            }
        ]
        
        self.results = []
    
    def test_tool_selection_accuracy(self):
        """æ¸¬è©¦å·¥å…·é¸æ“‡æº–ç¢ºæ€§"""
        print("ğŸ¯ æ¸¬è©¦1: æ™ºèƒ½å·¥å…·é¸æ“‡æº–ç¢ºæ€§")
        print("=" * 50)
        
        correct_selections = 0
        total_tests = 0
        
        for i, test_case in enumerate(self.test_cases, 1):
            print(f"\næ¸¬è©¦æ¡ˆä¾‹ {i}: {test_case['description']}")
            print(f"å•é¡Œ: {test_case['question']}")
            
            # åŸ·è¡Œå·¥å…·é¸æ“‡
            selection_result = select_best_tool(test_case['question'])
            
            primary_tool = selection_result['hybrid_strategy']['primary_tool']
            secondary_tools = selection_result['hybrid_strategy']['secondary_tools']
            execution_order = selection_result['hybrid_strategy']['execution_order']
            
            print(f"é¸æ“‡çµæœ:")
            print(f"  ä¸»å·¥å…·: {primary_tool.value}")
            print(f"  è¼”åŠ©å·¥å…·: {[tool.value for tool in secondary_tools]}")
            print(f"  åŸ·è¡Œé †åº: {[tool.value for tool in execution_order]}")
            print(f"  ä¿¡å¿ƒåº¦: {selection_result['confidence']:.2f}")
            
            # æª¢æŸ¥æº–ç¢ºæ€§
            if test_case['expected_primary']:
                is_correct = primary_tool == test_case['expected_primary']
                correct_selections += 1 if is_correct else 0
                total_tests += 1
                
                status = "âœ… æ­£ç¢º" if is_correct else "âŒ éŒ¯èª¤"
                print(f"  é æœŸä¸»å·¥å…·: {test_case['expected_primary'].value}")
                print(f"  çµæœ: {status}")
            else:
                print(f"  çµæœ: ğŸ” éœ€è¦é€²ä¸€æ­¥åˆ†æ")
            
            # ä¿å­˜çµæœ
            self.results.append({
                "test_case": test_case,
                "selection_result": selection_result,
                "is_correct": is_correct if test_case['expected_primary'] else None
            })
        
        if total_tests > 0:
            accuracy = correct_selections / total_tests
            print(f"\nğŸ“Š å·¥å…·é¸æ“‡æº–ç¢ºç‡: {accuracy:.2%} ({correct_selections}/{total_tests})")
        
        return accuracy if total_tests > 0 else 0
    
    def test_learning_feedback(self):
        """æ¸¬è©¦å­¸ç¿’åé¥‹æ©Ÿåˆ¶"""
        print("\nğŸ§  æ¸¬è©¦2: å­¸ç¿’åé¥‹æ©Ÿåˆ¶")
        print("=" * 50)
        
        # æ¨¡æ“¬ä¸€äº›åŸ·è¡Œçµæœ
        feedback_cases = [
            {
                "question": "ä»€éº¼æ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                "result": ExecutionResult.SUCCESS,
                "score": 0.9,
                "description": "æˆåŠŸæ¡ˆä¾‹"
            },
            {
                "question": "æœ€æ–°çš„é‡å­è¨ˆç®—çªç ´æ˜¯ä»€éº¼ï¼Ÿ",
                "result": ExecutionResult.PARTIAL_SUCCESS,
                "score": 0.6,
                "description": "éƒ¨åˆ†æˆåŠŸ"
            },
            {
                "question": "å¹«æˆ‘å‰µå»ºä¸€å€‹è¤‡é›œçš„æ•¸æ“šåˆ†æå ±å‘Š",
                "result": ExecutionResult.FAILURE,
                "score": 0.2,
                "description": "å¤±æ•—æ¡ˆä¾‹"
            }
        ]
        
        print("è¨˜éŒ„åŸ·è¡Œçµæœ...")
        for case in feedback_cases:
            # ç²å–å·¥å…·é¸æ“‡
            selection = select_best_tool(case['question'])
            
            # è¨˜éŒ„åŸ·è¡Œçµæœ
            record_tool_execution(
                question=case['question'],
                tool_selection=selection,
                result=case['result'],
                success_score=case['score'],
                execution_time=1.5
            )
            
            print(f"  {case['description']}: {case['result'].value} (åˆ†æ•¸: {case['score']})")
        
        # ç²å–å­¸ç¿’çµ±è¨ˆ
        stats = get_learning_statistics()
        print(f"\nğŸ“ˆ å­¸ç¿’çµ±è¨ˆ:")
        print(f"  ç¸½è¨˜éŒ„æ•¸: {stats['total_records']}")
        print(f"  æ•´é«”æˆåŠŸç‡: {stats['overall_success_rate']:.2%}")
        print(f"  å·¥å…·æ¬Šé‡æ›´æ–°: {len(stats['tool_weights'])} å€‹å·¥å…·")
        
        return stats
    
    def test_fallback_mechanism(self):
        """æ¸¬è©¦å…œåº•æ©Ÿåˆ¶"""
        print("\nğŸ›¡ï¸ æ¸¬è©¦3: å…œåº•æ©Ÿåˆ¶è§¸ç™¼")
        print("=" * 50)
        
        # æ¨¡æ“¬é€£çºŒå¤±æ•—
        failure_cases = [
            "å‰µå»ºä¸€å€‹å…¨æ–°çš„å€å¡Šéˆæ‡‰ç”¨",
            "è¨­è¨ˆä¸€å€‹ç«æ˜Ÿæ®–æ°‘åœ°çš„ç”Ÿæ…‹ç³»çµ±",
            "ç™¼æ˜ä¸€å€‹æ™‚é–“æ—…è¡Œè£ç½®"
        ]
        
        print("æ¨¡æ“¬é€£çºŒå¤±æ•—æ¡ˆä¾‹...")
        for i, question in enumerate(failure_cases, 1):
            selection = select_best_tool(question)
            
            # è¨˜éŒ„å¤±æ•—
            record_tool_execution(
                question=question,
                tool_selection=selection,
                result=ExecutionResult.COMPLETE_FAILURE,
                success_score=0.0,
                execution_time=2.0,
                error_message="æ‰€æœ‰å·¥å…·éƒ½ç„¡æ³•è™•ç†æ­¤å•é¡Œ"
            )
            
            print(f"  å¤±æ•—æ¡ˆä¾‹ {i}: {question[:30]}...")
        
        # æª¢æŸ¥å…œåº•æ©Ÿåˆ¶
        fallback_check = check_fallback_needed(
            question="å‰µå»ºä¸€å€‹é©å‘½æ€§çš„AIç³»çµ±",
            failed_tools=["gemini", "claude", "sequential_thinking", "webagent"]
        )
        
        print(f"\nğŸ” å…œåº•æ©Ÿåˆ¶æª¢æŸ¥:")
        print(f"  æ˜¯å¦è§¸ç™¼å…œåº•: {fallback_check['should_fallback']}")
        
        if fallback_check['should_fallback']:
            strategy = fallback_check['fallback_strategy']
            print(f"  å»ºè­°ç­–ç•¥: {strategy['strategy']}")
            print(f"  è™•ç†å±¤ç´š: ç¬¬{strategy['level']}å±¤")
            print(f"  æè¿°: {strategy['description']}")
            
            if 'recommended_tools' in strategy:
                print(f"  æ¨è–¦MCPå·¥å…·: {strategy['recommended_tools']}")
            elif 'recommended_services' in strategy:
                print(f"  æ¨è–¦å¤–éƒ¨æœå‹™: {strategy['recommended_services']}")
        
        return fallback_check
    
    def test_mcp_tool_recommendations(self):
        """æ¸¬è©¦MCPå·¥å…·æ¨è–¦"""
        print("\nğŸ”§ æ¸¬è©¦4: MCPå·¥å…·æ¨è–¦")
        print("=" * 50)
        
        mcp_test_cases = [
            {
                "question": "æˆ‘éœ€è¦è™•ç†ä¸€å€‹éå¸¸é•·çš„æ–‡æª”ï¼ŒåŒ…å«è¤‡é›œçš„ä¸Šä¸‹æ–‡é—œä¿‚",
                "failed_tools": ["gemini", "claude"],
                "expected_mcp": "infinite_context_adapter"
            },
            {
                "question": "å¹«æˆ‘è¨­è¨ˆä¸€å€‹è‡ªå‹•åŒ–çš„å·¥ä½œæµç¨‹ä¾†è™•ç†æ—¥å¸¸ä»»å‹™",
                "failed_tools": ["webagent"],
                "expected_mcp": "intelligent_workflow_engine"
            },
            {
                "question": "æˆ‘æƒ³è¦ç³»çµ±èƒ½å¤ è¨˜ä½æˆ‘å€‘ä¹‹å‰çš„æ‰€æœ‰å°è©±ä¸¦å¾ä¸­å­¸ç¿’",
                "failed_tools": ["sequential_thinking"],
                "expected_mcp": "supermemory_adapter"
            }
        ]
        
        for i, test_case in enumerate(mcp_test_cases, 1):
            print(f"\nMCPæ¨è–¦æ¡ˆä¾‹ {i}:")
            print(f"å•é¡Œ: {test_case['question']}")
            print(f"å·²å¤±æ•—å·¥å…·: {test_case['failed_tools']}")
            
            recommendations = get_mcp_tool_suggestions(
                test_case['question'], 
                test_case['failed_tools']
            )
            
            print(f"æ¨è–¦çµæœ:")
            for j, rec in enumerate(recommendations, 1):
                print(f"  {j}. {rec['tool_name']}")
                print(f"     åŒ¹é…åˆ†æ•¸: {rec['match_score']}")
                print(f"     åŒ¹é…é—œéµè©: {rec['matched_keywords']}")
                print(f"     æè¿°: {rec['description']}")
                print(f"     ä¿¡å¿ƒåº¦: {rec['confidence']:.2f}")
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«é æœŸçš„MCPå·¥å…·
            recommended_tools = [rec['tool_name'] for rec in recommendations]
            if test_case['expected_mcp'] in recommended_tools:
                print(f"  âœ… æ­£ç¢ºæ¨è–¦äº† {test_case['expected_mcp']}")
            else:
                print(f"  âŒ æœªæ¨è–¦é æœŸçš„ {test_case['expected_mcp']}")
        
        return recommendations
    
    def run_comprehensive_test(self):
        """é‹è¡Œç¶œåˆæ¸¬è©¦"""
        print("ğŸš€ PowerAutomation æ„åœ–ç†è§£æ•ˆæœç¶œåˆæ¸¬è©¦")
        print("=" * 60)
        
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        accuracy = self.test_tool_selection_accuracy()
        learning_stats = self.test_learning_feedback()
        fallback_result = self.test_fallback_mechanism()
        mcp_recommendations = self.test_mcp_tool_recommendations()
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        print("\nğŸ“‹ æ¸¬è©¦ç¸½çµå ±å‘Š")
        print("=" * 60)
        print(f"âœ… å·¥å…·é¸æ“‡æº–ç¢ºç‡: {accuracy:.2%}")
        print(f"ğŸ§  å­¸ç¿’è¨˜éŒ„æ•¸é‡: {learning_stats['total_records']}")
        print(f"ğŸ›¡ï¸ å…œåº•æ©Ÿåˆ¶: {'æ­£å¸¸å·¥ä½œ' if fallback_result['should_fallback'] else 'å¾…è§¸ç™¼'}")
        print(f"ğŸ”§ MCPæ¨è–¦åŠŸèƒ½: {'æ­£å¸¸å·¥ä½œ' if mcp_recommendations else 'éœ€è¦æ”¹é€²'}")
        
        # æ•´é«”è©•åˆ†
        overall_score = (
            accuracy * 0.4 +  # å·¥å…·é¸æ“‡40%
            (1.0 if learning_stats['total_records'] > 0 else 0.0) * 0.3 +  # å­¸ç¿’æ©Ÿåˆ¶30%
            (1.0 if fallback_result['should_fallback'] else 0.5) * 0.2 +  # å…œåº•æ©Ÿåˆ¶20%
            (1.0 if mcp_recommendations else 0.0) * 0.1  # MCPæ¨è–¦10%
        )
        
        print(f"\nğŸ¯ æ•´é«”è©•åˆ†: {overall_score:.2%}")
        
        if overall_score >= 0.8:
            print("ğŸ‰ æ„åœ–ç†è§£ç³»çµ±è¡¨ç¾å„ªç§€ï¼")
        elif overall_score >= 0.6:
            print("ğŸ‘ æ„åœ–ç†è§£ç³»çµ±è¡¨ç¾è‰¯å¥½ï¼Œæœ‰æ”¹é€²ç©ºé–“")
        else:
            print("âš ï¸ æ„åœ–ç†è§£ç³»çµ±éœ€è¦é€²ä¸€æ­¥å„ªåŒ–")
        
        return {
            "accuracy": accuracy,
            "learning_stats": learning_stats,
            "fallback_result": fallback_result,
            "mcp_recommendations": mcp_recommendations,
            "overall_score": overall_score
        }

if __name__ == "__main__":
    tester = IntentUnderstandingTester()
    results = tester.run_comprehensive_test()

